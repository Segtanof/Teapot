{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loading data\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#for llm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#similarity\n",
    "import regex as re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "\n",
    "#counting\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the folder name with current date and time\n",
    "folder_name = 'results/task_match_'+datetime.now().strftime(\"%d%m_%H%M\")+\"/\"\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset and drop columns\n",
    "job_statements = pd.read_excel(\"datasets/task_statements.xlsx\")\n",
    "job_statements.columns = job_statements.columns.str.lower()\n",
    "job_statements = job_statements.drop(labels=[\"incumbents responding\",\"date\",\"domain source\"], axis=1).rename(columns={\"o*net-soc code\":\"code\", \"task type\":\"type\", \"task id\": \"id\", \"task\":\"ref_task\"})\n",
    "job_statements = job_statements[~job_statements[\"type\"].str.contains(\"Supplemental\", case=False, na=True)]\n",
    "job_statements[\"ind\"] = job_statements[\"code\"].str[:2]\n",
    "job_statements = job_statements.groupby(\"title\").agg({\"ref_task\":list, \"ind\": \"first\"}).reset_index().sort_values(\"ind\")\n",
    "sampled_occupation = job_statements.groupby('ind', group_keys=False).sample(frac=0.05, random_state=1) #43 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customs Brokers',\n",
       " 'Training and Development Managers',\n",
       " 'Cooks, Institution and Cafeteria']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for trial\n",
    "trial_df = sampled_occupation.sample(3, random_state= 1)\n",
    "test_sample_list =[trial_df.iloc[x][\"title\"] for x in range(3)]\n",
    "test_sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get reference description\n",
    "def get_des (title):\n",
    "    task_list = sampled_occupation.query(\"title == @title\")[\"ref_task\"].iloc[0]\n",
    "    return task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke llm to generate tasks\n",
    "def task_gen(title, model, system = None):\n",
    "    json_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"occupation\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"tasks\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"minItems\": len(get_des(title)),\n",
    "                \"maxItems\": len(get_des(title))\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"occupation\", \"tasks\"]\n",
    "    }\n",
    "\n",
    "    #initialize model\n",
    "\n",
    "    query = \"List out exactly \"+str(len(get_des(title)))+\" task statements that the occupation \\\"\"+ title +\"\\\" would perform at work.Make sure each statement is unique and different from one another.\"\n",
    "\n",
    "    if system == None:\n",
    "        prompt_template = ChatPromptTemplate([\n",
    "            (\"human\",\"{input}\")\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        prompt_template = ChatPromptTemplate([\n",
    "            (\"system\", system),\n",
    "            (\"human\",\"{input}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    llm = model.with_structured_output(schema=json_schema, method=\"json_schema\")\n",
    "\n",
    "    prompt = prompt_template.invoke({\"input\": query, \"title\": title})\n",
    "    # keep running until the number of parsed tasks is equal to the number of reference tasks\n",
    "    for i in range (3):\n",
    "        response = llm.invoke(prompt)\n",
    "        #parse response\n",
    "        try:\n",
    "            parsed = json.loads(response[\"tasks\"])\n",
    "            print('parsed json')\n",
    "        except:\n",
    "            print('not json')\n",
    "            try:\n",
    "               parsed = response[\"tasks\"]\n",
    "               print('parsed string')\n",
    "            except:\n",
    "                print('not string')\n",
    "                continue\n",
    "        try:\n",
    "            if len(parsed) == len(get_des(title)):\n",
    "                return parsed\n",
    "            else:\n",
    "                print('not equal, parsed:', len(parsed), 'ref:', len(get_des(title)))\n",
    "        except Exception as e:\n",
    "            #try 3 more times, and if it still fails, return the parsed\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre process text\n",
    "def preProcessText(text=list):\n",
    "\tprocessed = []\n",
    "\tfor doc in text:\n",
    "\t\tdoc = re.sub(r\"\\\\n\", \"\", doc)\n",
    "\t\tdoc = re.sub(r\"\\W\", \" \", doc) #remove non words char\n",
    "\t\tdoc = re.sub(r\"\\d\",\" \", doc) #remove digits char\n",
    "\t\tdoc = re.sub(r'\\s+[a-z]\\s+', \" \", doc) # remove a single char\n",
    "\t\tdoc = re.sub(r'^[a-z]\\s+', \"\", doc) #remove a single character at the start of a document\n",
    "\t\tdoc = re.sub(r'\\s+', \" \", doc)  #replace an extra space with a single space\n",
    "\t\tdoc = re.sub(r'^\\s', \"\", doc) # remove space at the start of a doc\n",
    "\t\tdoc = re.sub(r'\\s$', \"\", doc) # remove space at the end of a document\n",
    "\t\tprocessed.append(doc.lower())\n",
    "\treturn processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get similarity score\n",
    "def sbert(ref, gen):\n",
    "    sim_model = SentenceTransformer(\"all-mpnet-base-v2\", similarity_fn_name=\"cosine\")\n",
    "\n",
    "    # Compute embeddings for both lists\n",
    "    embeddings_ref = sim_model.encode(ref)\n",
    "    embeddings_gen = sim_model.encode(gen)\n",
    "\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = sim_model.similarity(embeddings_ref, embeddings_gen).numpy()\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix and reorder them based on the hungarian algorithm\n",
    "def match(ref, gen):\n",
    "    try:\n",
    "        ref_clean = preProcessText(ref)\n",
    "        gen_clean = preProcessText(gen)\n",
    "        matrix = sbert(ref_clean, gen_clean)\n",
    "        row_ind, col_ind = linear_sum_assignment(1 - matrix)  # Minimize cost (1 - similarity)\n",
    "        assigned_similarities = matrix[row_ind, col_ind]\n",
    "        return np.mean(assigned_similarities), matrix, row_ind.tolist(), col_ind.tolist()\n",
    "    except:\n",
    "        print('error in matching' + ref[0])\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### packaging things for repeated excution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the process\n",
    "model = ChatOllama(model=\"llama3.2\", temperature=1)\n",
    "system_prompt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:12<00:24, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:17<00:08,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:24<00:00,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ref_task</th>\n",
       "      <th>ind</th>\n",
       "      <th>gen_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Customs Brokers</td>\n",
       "      <td>[Prepare and process import and export documen...</td>\n",
       "      <td>13</td>\n",
       "      <td>[Conduct inspections of shipments to verify co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>Training and Development Managers</td>\n",
       "      <td>[Analyze training needs to develop new trainin...</td>\n",
       "      <td>11</td>\n",
       "      <td>[Design and implement comprehensive training p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Cooks, Institution and Cafeteria</td>\n",
       "      <td>[Monitor and record food temperatures to ensur...</td>\n",
       "      <td>35</td>\n",
       "      <td>[Preparation of food according to recipes and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "203                    Customs Brokers   \n",
       "833  Training and Development Managers   \n",
       "178   Cooks, Institution and Cafeteria   \n",
       "\n",
       "                                              ref_task ind  \\\n",
       "203  [Prepare and process import and export documen...  13   \n",
       "833  [Analyze training needs to develop new trainin...  11   \n",
       "178  [Monitor and record food temperatures to ensur...  35   \n",
       "\n",
       "                                              gen_task  \n",
       "203  [Conduct inspections of shipments to verify co...  \n",
       "833  [Design and implement comprehensive training p...  \n",
       "178  [Preparation of food according to recipes and ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke llm for each title\n",
    "for title in tqdm(test_sample_list):\n",
    "    generated_statements = task_gen(title, model, system_prompt)\n",
    "    trial_df.loc[trial_df[\"title\"] == title, \"gen_task\"] = pd.Series([generated_statements]).values\n",
    "result_df = trial_df.reset_index(drop=True)\n",
    "result_df[[\"score\", \"matrix\", \"ref_order\", \"gen_order\"]] = result_df.apply(lambda row: match(row[\"ref_task\"], row[\"gen_task\"]), axis=1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "with open(folder_name + '/no_prompt.json', 'w') as f:\n",
    "    f.write(result_df.to_json(index=True))\n",
    "\n",
    "with open(folder_name + '/sys_prompt.txt', 'w') as f:\n",
    "    f.write(system_prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
