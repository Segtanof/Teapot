{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for loading data\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#for llm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#similarity\n",
    "import regex as re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "\n",
    "#counting\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the folder name with current date and time\n",
    "folder_name = 'results/task_match_'+datetime.now().strftime(\"%d%m_%H%M\")+\"/\"\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "# read dataset and drop columns\n",
    "job_statements = pd.read_excel(\"datasets/task_statements.xlsx\")\n",
    "job_statements.columns = job_statements.columns.str.lower()\n",
    "job_statements = job_statements.drop(labels=[\"incumbents responding\",\"date\",\"domain source\"], axis=1).rename(columns={\"o*net-soc code\":\"code\", \"task type\":\"type\", \"task id\": \"id\", \"task\":\"ref_task\"})\n",
    "job_statements = job_statements[job_statements[\"type\"].notna()]\n",
    "job_statements[\"ind\"] = job_statements[\"code\"].str[:2]\n",
    "job_statements = job_statements.groupby(\"title\").agg({\"ref_task\":list, \"ind\": \"first\"}).reset_index().sort_values(\"ind\")\n",
    "job_statements\n",
    "print(len(job_statements))\n",
    "sampled_occupation = job_statements.groupby('ind', group_keys=False).sample(frac=0.05, random_state=1) #43 samples\n",
    "sampled_occupation\n",
    "print(len(sampled_occupation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 3 rows of the sampled_occupation DataFrame as JSON\n",
    "sampled_occupation.head(3).to_json(\"sampled_occupation_sample.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ref_task</th>\n",
       "      <th>ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Lodging Managers</td>\n",
       "      <td>[Answer inquiries pertaining to hotel policies...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>Spa Managers</td>\n",
       "      <td>[Respond to customer inquiries or complaints.,...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>Training and Development Managers</td>\n",
       "      <td>[Analyze training needs to develop new trainin...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Customs Brokers</td>\n",
       "      <td>[Prepare and process import and export documen...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Government Property Inspectors and Investigators</td>\n",
       "      <td>[Prepare correspondence, reports of inspection...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>Video Game Designers</td>\n",
       "      <td>[Balance and adjust gameplay experiences to en...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Nanosystems Engineers</td>\n",
       "      <td>[Provide scientific or technical guidance or e...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Industrial Engineers</td>\n",
       "      <td>[Estimate production costs, cost saving method...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Surveying and Mapping Technicians</td>\n",
       "      <td>[Position and hold the vertical rods, or targe...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Biochemists and Biophysicists</td>\n",
       "      <td>[Share research findings by writing scientific...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Chemical Technicians</td>\n",
       "      <td>[Conduct chemical or physical laboratory tests...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Animal Scientists</td>\n",
       "      <td>[Study nutritional requirements of animals and...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Child, Family, and School Social Workers</td>\n",
       "      <td>[Maintain case history records and prepare rep...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Library Science Teachers, Postsecondary</td>\n",
       "      <td>[Conduct research in a particular field of kno...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>Sociology Teachers, Postsecondary</td>\n",
       "      <td>[Evaluate and grade students' class work, assi...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Business Teachers, Postsecondary</td>\n",
       "      <td>[Prepare and deliver lectures to undergraduate...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>Talent Directors</td>\n",
       "      <td>[Audition and interview performers to match th...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Commercial and Industrial Designers</td>\n",
       "      <td>[Prepare sketches of ideas, detailed drawings,...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Psychiatric Technicians</td>\n",
       "      <td>[Provide nursing, psychiatric, or personal car...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Radiologists</td>\n",
       "      <td>[Prepare comprehensive interpretive reports of...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Preventive Medicine Physicians</td>\n",
       "      <td>[Direct or manage prevention programs in speci...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Ophthalmic Medical Technicians</td>\n",
       "      <td>[Take and document patients' medical histories...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Occupational Therapy Aides</td>\n",
       "      <td>[Encourage patients and attend to their physic...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Crossing Guards and Flaggers</td>\n",
       "      <td>[Direct or escort pedestrians across streets, ...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Cooks, Short Order</td>\n",
       "      <td>[Clean food preparation equipment, work areas,...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Gambling Dealers</td>\n",
       "      <td>[Pay winnings or collect losing bets as establ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Insurance Sales Agents</td>\n",
       "      <td>[Customize insurance programs to suit individu...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Insurance Claims and Policy Processing Clerks</td>\n",
       "      <td>[Prepare insurance claim forms or related docu...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Credit Authorizers, Checkers, and Clerks</td>\n",
       "      <td>[Keep records of customers' charges and paymen...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>Postal Service Mail Carriers</td>\n",
       "      <td>[Scan labels on letters or parcels to confirm ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>Log Graders and Scalers</td>\n",
       "      <td>[Evaluate log characteristics and determine gr...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Carpenters</td>\n",
       "      <td>[Follow established safety rules and regulatio...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Hazardous Materials Removal Workers</td>\n",
       "      <td>[Build containment areas prior to beginning ab...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Energy Auditors</td>\n",
       "      <td>[Identify and prioritize energy-saving measure...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Bicycle Repairers</td>\n",
       "      <td>[Install and adjust brakes and brake pads., He...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Avionics Technicians</td>\n",
       "      <td>[Test and troubleshoot instruments, components...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Molders, Shapers, and Casters, Except Metal an...</td>\n",
       "      <td>[Read work orders or examine parts to determin...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Printing Press Operators</td>\n",
       "      <td>[Start presses and pull proofs to check for in...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Power Plant Operators</td>\n",
       "      <td>[Control generator output to match the phase, ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Nuclear Power Reactor Operators</td>\n",
       "      <td>[Operate nuclear power reactors in accordance ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>Metal-Refining Furnace Operators and Tenders</td>\n",
       "      <td>[Regulate supplies of fuel and air, or control...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Ship Engineers</td>\n",
       "      <td>[Monitor engine, machinery, or equipment indic...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Air Traffic Controllers</td>\n",
       "      <td>[Inform pilots about nearby planes or potentia...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "478                                   Lodging Managers   \n",
       "778                                       Spa Managers   \n",
       "834                  Training and Development Managers   \n",
       "203                                    Customs Brokers   \n",
       "386   Government Property Inspectors and Investigators   \n",
       "857                               Video Game Designers   \n",
       "559                              Nanosystems Engineers   \n",
       "430                               Industrial Engineers   \n",
       "800                  Surveying and Mapping Technicians   \n",
       "75                       Biochemists and Biophysicists   \n",
       "122                               Chemical Technicians   \n",
       "35                                   Animal Scientists   \n",
       "127           Child, Family, and School Social Workers   \n",
       "467            Library Science Teachers, Postsecondary   \n",
       "769                  Sociology Teachers, Postsecondary   \n",
       "101                   Business Teachers, Postsecondary   \n",
       "805                                   Talent Directors   \n",
       "149                Commercial and Industrial Designers   \n",
       "680                            Psychiatric Technicians   \n",
       "694                                       Radiologists   \n",
       "668                     Preventive Medicine Physicians   \n",
       "592                     Ophthalmic Medical Technicians   \n",
       "584                         Occupational Therapy Aides   \n",
       "199                       Crossing Guards and Flaggers   \n",
       "181                                 Cooks, Short Order   \n",
       "365                                   Gambling Dealers   \n",
       "443                             Insurance Sales Agents   \n",
       "442      Insurance Claims and Policy Processing Clerks   \n",
       "195           Credit Authorizers, Checkers, and Clerks   \n",
       "657                       Postal Service Mail Carriers   \n",
       "479                            Log Graders and Scalers   \n",
       "113                                         Carpenters   \n",
       "392                Hazardous Materials Removal Workers   \n",
       "266                                    Energy Auditors   \n",
       "72                                   Bicycle Repairers   \n",
       "65                                Avionics Technicians   \n",
       "544  Molders, Shapers, and Casters, Except Metal an...   \n",
       "670                           Printing Press Operators   \n",
       "663                              Power Plant Operators   \n",
       "573                    Nuclear Power Reactor Operators   \n",
       "530       Metal-Refining Furnace Operators and Tenders   \n",
       "757                                     Ship Engineers   \n",
       "21                             Air Traffic Controllers   \n",
       "\n",
       "                                              ref_task ind  \n",
       "478  [Answer inquiries pertaining to hotel policies...  11  \n",
       "778  [Respond to customer inquiries or complaints.,...  11  \n",
       "834  [Analyze training needs to develop new trainin...  11  \n",
       "203  [Prepare and process import and export documen...  13  \n",
       "386  [Prepare correspondence, reports of inspection...  13  \n",
       "857  [Balance and adjust gameplay experiences to en...  15  \n",
       "559  [Provide scientific or technical guidance or e...  17  \n",
       "430  [Estimate production costs, cost saving method...  17  \n",
       "800  [Position and hold the vertical rods, or targe...  17  \n",
       "75   [Share research findings by writing scientific...  19  \n",
       "122  [Conduct chemical or physical laboratory tests...  19  \n",
       "35   [Study nutritional requirements of animals and...  19  \n",
       "127  [Maintain case history records and prepare rep...  21  \n",
       "467  [Conduct research in a particular field of kno...  25  \n",
       "769  [Evaluate and grade students' class work, assi...  25  \n",
       "101  [Prepare and deliver lectures to undergraduate...  25  \n",
       "805  [Audition and interview performers to match th...  27  \n",
       "149  [Prepare sketches of ideas, detailed drawings,...  27  \n",
       "680  [Provide nursing, psychiatric, or personal car...  29  \n",
       "694  [Prepare comprehensive interpretive reports of...  29  \n",
       "668  [Direct or manage prevention programs in speci...  29  \n",
       "592  [Take and document patients' medical histories...  29  \n",
       "584  [Encourage patients and attend to their physic...  31  \n",
       "199  [Direct or escort pedestrians across streets, ...  33  \n",
       "181  [Clean food preparation equipment, work areas,...  35  \n",
       "365  [Pay winnings or collect losing bets as establ...  39  \n",
       "443  [Customize insurance programs to suit individu...  41  \n",
       "442  [Prepare insurance claim forms or related docu...  43  \n",
       "195  [Keep records of customers' charges and paymen...  43  \n",
       "657  [Scan labels on letters or parcels to confirm ...  43  \n",
       "479  [Evaluate log characteristics and determine gr...  45  \n",
       "113  [Follow established safety rules and regulatio...  47  \n",
       "392  [Build containment areas prior to beginning ab...  47  \n",
       "266  [Identify and prioritize energy-saving measure...  47  \n",
       "72   [Install and adjust brakes and brake pads., He...  49  \n",
       "65   [Test and troubleshoot instruments, components...  49  \n",
       "544  [Read work orders or examine parts to determin...  51  \n",
       "670  [Start presses and pull proofs to check for in...  51  \n",
       "663  [Control generator output to match the phase, ...  51  \n",
       "573  [Operate nuclear power reactors in accordance ...  51  \n",
       "530  [Regulate supplies of fuel and air, or control...  51  \n",
       "757  [Monitor engine, machinery, or equipment indic...  53  \n",
       "21   [Inform pilots about nearby planes or potentia...  53  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sampled_occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customs Brokers']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for trial\n",
    "trial_df = sampled_occupation.sample(1, random_state= 1)\n",
    "test_sample_list =[trial_df.iloc[x][\"title\"] for x in range(len(trial_df))]\n",
    "test_sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get reference description\n",
    "def get_des (title):\n",
    "    task_list = sampled_occupation.query(\"title == @title\")[\"ref_task\"].iloc[0]\n",
    "    return task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke llm to generate tasks\n",
    "def task_gen(title, model, system = None):\n",
    "    json_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"occupation\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"tasks\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"minItems\": len(get_des(title)),\n",
    "                \"maxItems\": len(get_des(title))\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"occupation\", \"tasks\"]\n",
    "    }\n",
    "\n",
    "    #initialize model\n",
    "\n",
    "    query = \"List out exactly \"+str(len(get_des(title)))+\" task statements that the occupation \\\"\"+ title +\"\\\" would perform at work.Make sure each statement is unique and different from one another.\"\n",
    "\n",
    "    if system == None:\n",
    "        prompt_template = ChatPromptTemplate([\n",
    "            (\"human\",\"{input}\")\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        prompt_template = ChatPromptTemplate([\n",
    "            (\"system\", system),\n",
    "            (\"human\",\"{input}\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    llm = model.with_structured_output(schema=json_schema, method=\"json_schema\")\n",
    "\n",
    "    prompt = prompt_template.invoke({\"input\": query, \"title\": title})\n",
    "    # keep running until the number of parsed tasks is equal to the number of reference tasks\n",
    "    for i in range (3):\n",
    "        response = llm.invoke(prompt)\n",
    "        #parse response\n",
    "        try:\n",
    "            parsed = json.loads(response[\"tasks\"])\n",
    "            print('parsed json')\n",
    "        except:\n",
    "            print('not json')\n",
    "            try:\n",
    "               parsed = response[\"tasks\"]\n",
    "               print('parsed string')\n",
    "            except:\n",
    "                print('not string')\n",
    "                continue\n",
    "        try:\n",
    "            if len(parsed) == len(get_des(title)):\n",
    "                return parsed\n",
    "            else:\n",
    "                print('not equal, parsed:', len(parsed), 'ref:', len(get_des(title)))\n",
    "        except Exception as e:\n",
    "            #try 3 more times, and if it still fails, return the parsed\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre process text\n",
    "def preProcessText(text=list):\n",
    "\tprocessed = []\n",
    "\tfor doc in text:\n",
    "\t\tdoc = re.sub(r\"\\\\n\", \"\", doc)\n",
    "\t\tdoc = re.sub(r\"\\W\", \" \", doc) #remove non words char\n",
    "\t\tdoc = re.sub(r\"\\d\",\" \", doc) #remove digits char\n",
    "\t\tdoc = re.sub(r'\\s+[a-z]\\s+', \" \", doc) # remove a single char\n",
    "\t\tdoc = re.sub(r'^[a-z]\\s+', \"\", doc) #remove a single character at the start of a document\n",
    "\t\tdoc = re.sub(r'\\s+', \" \", doc)  #replace an extra space with a single space\n",
    "\t\tdoc = re.sub(r'^\\s', \"\", doc) # remove space at the start of a doc\n",
    "\t\tdoc = re.sub(r'\\s$', \"\", doc) # remove space at the end of a document\n",
    "\t\tprocessed.append(doc.lower())\n",
    "\treturn processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get similarity score\n",
    "def sbert(ref, gen):\n",
    "    sim_model = SentenceTransformer(\"all-mpnet-base-v2\", similarity_fn_name=\"cosine\")\n",
    "\n",
    "    # Compute embeddings for both lists\n",
    "    embeddings_ref = sim_model.encode(ref)\n",
    "    embeddings_gen = sim_model.encode(gen)\n",
    "\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarities = sim_model.similarity(embeddings_ref, embeddings_gen).numpy()\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix and reorder them based on the hungarian algorithm\n",
    "def match(ref, gen):\n",
    "    try:\n",
    "        ref_clean = preProcessText(ref)\n",
    "        gen_clean = preProcessText(gen)\n",
    "        matrix = sbert(ref_clean, gen_clean)\n",
    "        row_ind, col_ind = linear_sum_assignment(1 - matrix)  # Minimize cost (1 - similarity)\n",
    "        assigned_similarities = matrix[row_ind, col_ind]\n",
    "        return np.mean(assigned_similarities), matrix, row_ind.tolist(), col_ind.tolist()\n",
    "    except:\n",
    "        print('error in matching' + ref[0])\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### packaging things for repeated excution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the process\n",
    "llama = ChatOllama(model=\"llama3.2\", temperature=1, base_url=\"http://127.0.0.1:11434\")\n",
    "mistral = ChatOllama(model=\"llama3.2\", temperature=1, base_url=\"http://127.0.0.1:11434\")\n",
    "model_list = [llama, mistral]\n",
    "prompts = {\"no_prompt\": None, \n",
    "           \"prompt1\": \"You are an expert of this occupation: \\\"{title}\\\". Your task is to generate clear and concise task descriptions that reflect common responsibilities in this profession. Each description should be specific, action-oriented, and use professional language. Avoid unnecessary details—focus on the core action and purpose of the task.\", \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "with open(folder_name + '/no_prompt.json', 'w') as f:\n",
    "    f.write(result_df.to_json(index=True))\n",
    "\n",
    "with open(folder_name + '/sys_prompt.txt', 'w') as f:\n",
    "    f.write(system_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no prompt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert of this occupation: \"{title}\". Your task is to generate clear and concise task descriptions that reflect common responsibilities in this profession. Each description should be specific, action-oriented, and use professional language. Avoid unnecessary details—focus on the core action and purpose of the task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:19<00:00, 19.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:24<00:00, 24.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:31<00:00, 31.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customs Brokers1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not json\n",
      "parsed string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_prompt_write_prompt: 0.0003 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_llm_invoke: 17.3758 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_save_result_json: 0.0008 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_similarity_computation: 2.8513 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_save_sim_json: 0.0022 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_llm_invoke: 16.1228 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_save_result_json: 0.0006 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_similarity_computation: 2.8331 seconds\n",
      "no_prompt_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_save_sim_json: 0.0029 seconds\n",
      "prompt1_write_prompt: 0.0023 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_llm_invoke: 31.2185 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_save_result_json: 0.0006 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_similarity_computation: 2.7439 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_save_sim_json: 0.0021 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_llm_invoke: 18.8499 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_save_result_json: 0.0006 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_similarity_computation: 3.2006 seconds\n",
      "prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_1_save_sim_json: 0.0029 seconds\n",
      "\n",
      "Slowest step: prompt1_model='llama3.2' temperature=1.0 base_url='http://127.0.0.1:11434'_0_llm_invoke took 31.2185 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "times = {}\n",
    "\n",
    "for name, prompt in prompts.items():\n",
    "    # Step 1: Writing system prompt to file\n",
    "    start = time.perf_counter()\n",
    "    if prompt != None:\n",
    "        with open(folder_name + '/sys_prompt.txt', 'a') as f:\n",
    "            f.write(prompt + '\\n')\n",
    "        print(prompt)\n",
    "    else:\n",
    "        print(\"no prompt\")\n",
    "    times[f'{name}_write_prompt'] = time.perf_counter() - start\n",
    "\n",
    "    for model in model_list:\n",
    "        for i in range(2):\n",
    "            # Step 2: LLM invocation and DataFrame update\n",
    "            start = time.perf_counter()\n",
    "            for title in tqdm(test_sample_list):\n",
    "                print(title + str(i))\n",
    "                generated_statements = task_gen(title, model, prompt)\n",
    "                trial_df.loc[trial_df[\"title\"] == title, \"gen_task\"] = pd.Series([generated_statements]).values\n",
    "            result_df = trial_df.reset_index(drop=True)\n",
    "            times[f'{name}_{model}_{i}_llm_invoke'] = time.perf_counter() - start\n",
    "\n",
    "            # Step 3: Save initial result DataFrame to JSON\n",
    "            start = time.perf_counter()\n",
    "            with open(folder_name + '/' + name + '_'+str(i)+'_result.json', 'w') as f:\n",
    "                f.write(result_df.to_json(index=True))\n",
    "            times[f'{name}_{model}_{i}_save_result_json'] = time.perf_counter() - start\n",
    "\n",
    "            # Step 4 & 5: Compute similarity scores and save to JSON\n",
    "            try:\n",
    "                # Step 4: Similarity computation (assuming match includes Hungarian algorithm)\n",
    "                start = time.perf_counter()\n",
    "                result_df[[\"score\", \"matrix\", \"ref_order\", \"gen_order\"]] = result_df.apply(\n",
    "                    lambda row: match(row[\"ref_task\"], row[\"gen_task\"]), axis=1\n",
    "                ).apply(pd.Series)\n",
    "                times[f'{name}_{model}_{i}_similarity_computation'] = time.perf_counter() - start\n",
    "\n",
    "                # Step 5: Save similarity result to JSON\n",
    "                start = time.perf_counter()\n",
    "                with open(folder_name + '/' + name + '_'+str(i)+'_sim.json', 'w') as f:\n",
    "                    f.write(result_df.to_json(index=True))\n",
    "                times[f'{name}_{model}_{i}_save_sim_json'] = time.perf_counter() - start\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "# Print timing results\n",
    "for step, duration in times.items():\n",
    "    print(f\"{step}: {duration:.4f} seconds\")\n",
    "\n",
    "# Optional: Find the slowest step\n",
    "slowest_step = max(times, key=times.get)\n",
    "print(f\"\\nSlowest step: {slowest_step} took {times[slowest_step]:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#for loading data\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "#for llm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "\n",
    "#similarity\n",
    "import regex as re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "\n",
    "#counting\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# computation\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging  # For logging to file and console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"execution_log.log\"),  # Log to file\n",
    "        logging.StreamHandler()  # Log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Generate the folder name with current date and time\n",
    "folder_name = 'results/task_match_'+datetime.now().strftime(\"%d%m_%H%M\")+\"/\"\n",
    "\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customs Brokers']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read dataset and drop columns\n",
    "job_statements = pd.read_excel(\"datasets/task_statements.xlsx\")\n",
    "job_statements.columns = job_statements.columns.str.lower()\n",
    "job_statements = job_statements.drop(labels=[\"incumbents responding\",\"date\",\"domain source\"], axis=1).rename(columns={\"o*net-soc code\":\"code\", \"task type\":\"type\", \"task id\": \"id\", \"task\":\"ref_task\"})\n",
    "job_statements = job_statements[job_statements[\"type\"].notna()]\n",
    "job_statements[\"ind\"] = job_statements[\"code\"].str[:2]\n",
    "job_statements = job_statements.groupby(\"title\").agg({\"ref_task\":list, \"ind\": \"first\"}).reset_index().sort_values(\"ind\")\n",
    "sampled_occupation = job_statements.groupby('ind', group_keys=False).sample(frac=0.05, random_state=1) #43 samples\n",
    "\n",
    "\n",
    "# %%\n",
    "#for trial\n",
    "trial_df = sampled_occupation.sample(1, random_state= 1)\n",
    "test_sample_list =[trial_df.iloc[x][\"title\"] for x in range(len(trial_df))]\n",
    "test_sample_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_title(args):\n",
    "    title, model, prompt = args\n",
    "    start_time = datetime.now()\n",
    "    tasks = task_gen(title, model, system=prompt)  # prompt as system\n",
    "    logging.info(f\"Single inference for {title}, duration: {datetime.now() - start_time}\")\n",
    "    return title, tasks  # Returns list of tasks\n",
    "\n",
    "# %%\n",
    "#get reference description\n",
    "def get_des (title):\n",
    "    task_list = sampled_occupation.query(\"title == @title\")[\"ref_task\"].iloc[0]\n",
    "    return task_list\n",
    "\n",
    "# %%\n",
    "#invoke llm to generate tasks\n",
    "def task_gen(title, model, system=None):\n",
    "    \"\"\"Generate exactly the required number of unique task statements for a title.\"\"\"\n",
    "    # Get reference task count (assumed function)\n",
    "    ref_task_count = len(get_des(title))\n",
    "    \n",
    "    # Define JSON schema\n",
    "    json_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"occupation\": {\"type\": \"string\"},\n",
    "            \"tasks\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"minItems\": ref_task_count,\n",
    "                \"maxItems\": ref_task_count\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"occupation\", \"tasks\"]\n",
    "    }\n",
    "\n",
    "    # Construct prompt\n",
    "    query = (\n",
    "        f\"List exactly {ref_task_count} unique task statements that the occupation '{title}' \"\n",
    "        \"would perform at work. Ensure each statement is distinct, concise, and relevant.\"\n",
    "    )\n",
    "    \n",
    "    # Use system prompt if provided, otherwise just human query\n",
    "    if system:\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "    else:\n",
    "        prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "\n",
    "    # Configure LLM with structured output\n",
    "    llm = model.with_structured_output(schema=json_schema, method=\"json_schema\")\n",
    "    prompt = prompt_template.invoke({\"input\": query})\n",
    "\n",
    "    # Invoke and parse response\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        # Expecting dict from with_structured_output\n",
    "        tasks = response[\"tasks\"]\n",
    "        \n",
    "        # Validate task count and uniqueness\n",
    "        if len(tasks) != ref_task_count:\n",
    "            logging.warning(f\"Task count mismatch for {title}: got {len(tasks)}, expected {ref_task_count}\")\n",
    "            return tasks  # Return anyway, handle downstream\n",
    "        if len(set(tasks)) < len(tasks):\n",
    "            logging.warning(f\"Duplicate tasks detected for {title}\")\n",
    "        \n",
    "        return tasks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate tasks for {title}: {e}\")\n",
    "        # Return dummy tasks to avoid breaking pipeline\n",
    "        return [f\"Error: Task {i+1} for {title}\" for i in range(ref_task_count)]\n",
    "        \n",
    "    \n",
    "def preProcessText(text):\n",
    "    \"\"\"Preprocess a list of text strings.\"\"\"\n",
    "    processed = []\n",
    "    for doc in text:\n",
    "        if not isinstance(doc, str):  # Handle non-string (e.g., list or NaN)\n",
    "            doc = str(doc)\n",
    "        doc = re.sub(r\"\\\\n\", \"\", doc)\n",
    "        doc = re.sub(r\"\\W\", \" \", doc)\n",
    "        doc = re.sub(r\"\\d\", \" \", doc)\n",
    "        doc = re.sub(r'\\s+[a-z]\\s+', \" \", doc)\n",
    "        doc = re.sub(r'^[a-z]\\s+', \"\", doc)\n",
    "        doc = re.sub(r'\\s+', \" \", doc)\n",
    "        doc = re.sub(r'^\\s', \"\", doc)\n",
    "        doc = re.sub(r'\\s$', \"\", doc)\n",
    "        processed.append(doc.lower())\n",
    "    return processed\n",
    "\n",
    "def sbert_batch(ref_list, gen_list):\n",
    "    \"\"\"Compute similarity scores for all ref and gen texts in one batch.\"\"\"\n",
    "    sim_model = SentenceTransformer(\"all-mpnet-base-v2\", similarity_fn_name=\"cosine\")\n",
    "    embeddings_ref = sim_model.encode(ref_list, batch_size=32)  # Batch embeddings\n",
    "    embeddings_gen = sim_model.encode(gen_list, batch_size=32)\n",
    "    similarities = sim_model.similarity(embeddings_ref, embeddings_gen).numpy()\n",
    "    return similarities\n",
    "\n",
    "def match_batch(ref_list, gen_list):\n",
    "    \"\"\"Batch process matching for multiple ref-gen pairs.\"\"\"\n",
    "    ref_clean = preProcessText(ref_list)\n",
    "    gen_clean = preProcessText(gen_list)\n",
    "    matrix = sbert_batch(ref_clean, gen_clean)\n",
    "    \n",
    "    # Process Hungarian algorithm per pair\n",
    "    results = []\n",
    "    for i in range(len(ref_list)):\n",
    "        row_matrix = matrix[i:i+1, i:i+1] if len(ref_list) == 1 else matrix[i, i].reshape(1, 1)  # Handle single pair\n",
    "        row_ind, col_ind = linear_sum_assignment(1 - row_matrix)  # Minimize cost\n",
    "        score = matrix[i, i]  # Diagonal score for single pair\n",
    "        results.append((score, row_matrix.tolist(), row_ind.tolist(), col_ind.tolist()))\n",
    "    return results\n",
    "\n",
    "def apply_match_batch(df):\n",
    "    \"\"\"Apply batched matching to the entire DataFrame.\"\"\"\n",
    "    ref_list = df[\"ref_task\"].tolist()\n",
    "    gen_list = df[\"gen_task\"].tolist()\n",
    "    results = match_batch(ref_list, gen_list)\n",
    "    scores, matrices, ref_orders, gen_orders = zip(*results)\n",
    "    df[\"score\"] = scores\n",
    "    df[\"matrix\"] = matrices\n",
    "    df[\"ref_order\"] = ref_orders\n",
    "    df[\"gen_order\"] = gen_orders\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_2 = ChatOllama(model=\"llama3.2\", temperature=1, base_url=\"http://127.0.0.1:11434\")\n",
    "llama3_1 = ChatOllama(model=\"llama3.1\", temperature=1, base_url=\"http://127.0.0.1:11434\")\n",
    "\n",
    "model_list = [llama3_2, llama3_1]\n",
    "\n",
    "prompts = {\"no_prompt\": None, \n",
    "           \"prompt1\": \"You are an expert of this occupation: \\\"{title}\\\". Your task is to generate clear and concise task descriptions that reflect common responsibilities in this profession. Each description should be specific, action-oriented, and use professional language. Avoid unnecessary details—focus on the core action and purpose of the task.\",}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 17:50:41,921 - Script started\n",
      "2025-03-19 17:50:41,921 - Processing model: llama3.2\n",
      "2025-03-19 17:50:42,271 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "llama3.2-no_prompt-0:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-19 17:50:49,152 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 17:51:21,044 - Single inference for Customs Brokers, duration: 0:00:32.083894\n",
      "llama3.2-no_prompt-0: 100%|██████████| 1/1 [00:32<00:00, 32.08s/it]\n",
      "2025-03-19 17:51:21,048 - ThreadPoolExecutor for llama3.2-no_prompt-0, duration: 0:00:32.087786\n",
      "llama3.2-no_prompt-1:   0%|          | 0/1 [00:00<?, ?it/s]2025-03-19 17:51:21,177 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 17:51:38,689 - Single inference for Customs Brokers, duration: 0:00:17.637842\n",
      "llama3.2-no_prompt-1:   0%|          | 0/1 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 21\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_sample_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_sample_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreadPoolExecutor for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, duration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m temp_df \u001b[38;5;241m=\u001b[39m trial_df\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.info(\"Script started\")\n",
    "for model in model_list:\n",
    "    model_name = model.model\n",
    "    logging.info(f\"Processing model: {model_name}\")\n",
    "    model.invoke(\"Warm-up prompt\")\n",
    "\n",
    "    for name, prompt in prompts.items():\n",
    "        if prompt:\n",
    "            start_time = datetime.now()\n",
    "            with open(f\"{folder_name}/sys_prompt.txt\", \"a\") as f:\n",
    "                f.write(prompt + \"\\n\")\n",
    "            logging.info(f\"Wrote prompt {name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "        all_results_df = trial_df.copy()\n",
    "        all_results_df[\"gen_task\"] = None  # Now a list of tasks\n",
    "        all_results_df[\"iteration\"] = None\n",
    "\n",
    "        for i in range(5):\n",
    "            start_time = datetime.now()\n",
    "            with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "                results = list(tqdm(\n",
    "                    executor.map(process_title, [(title, model, prompt) for title in test_sample_list]),\n",
    "                    total=len(test_sample_list),\n",
    "                    desc=f\"{model_name}-{name}-{i}\"\n",
    "                ))\n",
    "            logging.info(f\"ThreadPoolExecutor for {model_name}-{name}-{i}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "            temp_df = trial_df.copy()\n",
    "            for title, tasks in results:\n",
    "                temp_df.loc[temp_df[\"title\"] == title, \"gen_task\"] = pd.Series([tasks]).values  # Store as list\n",
    "            temp_df[\"iteration\"] = i\n",
    "            all_results_df = pd.concat([all_results_df, temp_df], ignore_index=True)\n",
    "\n",
    "        # Batch match (adjust for list of tasks)\n",
    "        start_time = datetime.now()\n",
    "        # Flatten gen_task lists to strings for matching (assuming one task per ref_task for simplicity)\n",
    "        all_results_df[\"gen_task_str\"] = all_results_df[\"gen_task\"].apply(lambda x: x[0] if x and len(x) > 0 else \"\")\n",
    "        all_results_df = apply_match_batch(all_results_df.rename(columns={\"gen_task_str\": \"gen_task\"}))\n",
    "        logging.info(f\"Batch matching for {model_name}-{name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "        # Save once\n",
    "        start_time = datetime.now()\n",
    "        all_results_df = all_results_df.reset_index(drop=True)\n",
    "        with open(f\"{folder_name}/{model_name}_{name}_results.json\", \"w\") as f:\n",
    "            f.write(all_results_df.to_json(index=True))\n",
    "        logging.info(f\"Wrote results JSON for {model_name}-{name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "logging.info(\"Script completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
