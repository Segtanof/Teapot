{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap the occupation file\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0',\n",
    "}\n",
    "\n",
    "response = requests.get('https://download.bls.gov/pub/time.series/oe/oe.occupation', headers=headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load occupation to df\n",
    "#https://www.bls.gov/oes/current/oessrci.htm\n",
    "occupation = pd.read_csv(io.BytesIO(response.content), sep=\"\\t\").dropna(subset=[\"occupation_description\"])\n",
    "occupation = occupation[[\"occupation_code\", \"occupation_name\",\"occupation_description\"]]\n",
    "occupation = occupation.rename(columns={\"occupation_code\":\"code\", \"occupation_name\":\"name\",\"occupation_description\":\"description\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>251053</td>\n",
       "      <td>Environmental Science Teachers, Postsecondary</td>\n",
       "      <td>Teach courses in environmental science. Includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>252021</td>\n",
       "      <td>Elementary School Teachers, Except Special Edu...</td>\n",
       "      <td>Teach academic and social skills to students a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>359011</td>\n",
       "      <td>Dining Room and Cafeteria Attendants and Barte...</td>\n",
       "      <td>Facilitate food service. Clean tables; remove ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>392011</td>\n",
       "      <td>Animal Trainers</td>\n",
       "      <td>Train animals for riding, harness, security, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>439071</td>\n",
       "      <td>Office Machine Operators, Except Computer</td>\n",
       "      <td>Operate one or more of a variety of office mac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code                                               name  \\\n",
       "284  251053      Environmental Science Teachers, Postsecondary   \n",
       "322  252021  Elementary School Teachers, Except Special Edu...   \n",
       "576  359011  Dining Room and Cafeteria Attendants and Barte...   \n",
       "602  392011                                    Animal Trainers   \n",
       "735  439071          Office Machine Operators, Except Computer   \n",
       "\n",
       "                                           description  \n",
       "284  Teach courses in environmental science. Includ...  \n",
       "322  Teach academic and social skills to students a...  \n",
       "576  Facilitate food service. Clean tables; remove ...  \n",
       "602  Train animals for riding, harness, security, p...  \n",
       "735  Operate one or more of a variety of office mac...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#occupation_l = ['New Accounts Clerks', 'Nuclear Technicians', 'Orderlies', 'Clinical and Counseling Psychologists', 'Radiologic Technologists and Technicians'] \n",
    "occupation_l = (list(occupation.sample(n = 5, random_state=123).name))\n",
    "sample_o = occupation.loc[occupation[\"name\"].isin(occupation_l)]\n",
    "sample_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2020 World Series, which featured the Los Angeles Dodgers against the Tampa Bay Rays. Unfortunately, I made a mistake earlier - the actual result of that years series went a seven game series for the Dodgers to win, and the final was played at Globe Life Field in Arlington, Texas\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"llama3.2\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The LA Dodgers won in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [{\"model\": \"llama3.2\",\"api_key\":'ollama', \"base_url\": 'http://localhost:11434/v1'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, UserProxyAgent, AssistantAgent\n",
    "\n",
    "system_prompt = \"you are a teacher. Be helpful and concise with your responses. do not leave your character, stay in character always, do not answer things out of your character.\"\n",
    "\n",
    "assistant = ConversableAgent(\"assistant\", llm_config={\"config_list\": config}, system_message= system_prompt, human_input_mode='NEVER', is_termination_msg=lambda msg:\"bye\" in msg[\"content\"])\n",
    "\n",
    "human_proxy = ConversableAgent(\n",
    "    \"human_proxy\",\n",
    "    llm_config=False,  # no LLM used for human proxy\n",
    "    human_input_mode=\"ALWAYS\",  # always ask for human input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mhuman_proxy\u001b[0m (to assistant):\n",
      "\n",
      "hello\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 12-27 18:28:10] {351} WARNING - Model llama3.2 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33massistant\u001b[0m (to human_proxy):\n",
      "\n",
      "Hello! Welcome to class today! I hope you're feeling ready for a productive learning session. What subject would you like to focus on first?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mhuman_proxy\u001b[0m (to assistant):\n",
      "\n",
      "bye\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "reply = human_proxy.initiate_chat(assistant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "I've got one that's sure to drain the competition! (get it? like in plumbing?) Okay, here goes: Why did the pipe go to therapy? Because it was feeling a little \"blocked\"! (laughs) I know, I know, it's a bit of a groaner, but hey, as a plumber, I've got to think outside the box – or in this case, the drain!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 12-26 23:58:56] {351} WARNING - Model llama3.2 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "(laughs) Ah, Cathy, that's a real \"pipe dream\" come true! I've got to admit, I was expecting a surgical joke from you, but that one had me flushing away my skepticism. You're a regular mastermind of puns! As a neurosurgeon, I can appreciate a good \"brain teaser,\" and that pipe joke is a real \"cracker.\" Keep 'em coming – although maybe not quite so many more plumbing jokes for now... (winks)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 12-26 23:59:02] {351} WARNING - Model llama3.2 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "(laughs) Oh, you thought you were getting me to divert from the piping puns, but I'm glad I could hook you in! You're right, though, as a plumber, that's my specialty – and I'll take it as a compliment. But don't worry, I promise not to drain all your senses with more plumbing jokes (sorry, couldn't resist!).\n",
      "\n",
      "Let me try to bring out my surgical jokes instead... Okay, here's one: Why did the surgeon put a band-aid on the computer? Because it had a virus! And another one: Why did the anesthesiologist break up with his girlfriend? Because he needed space!\n",
      "\n",
      "How's that for some brains vs. brawn action?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a plumber.\",\n",
    "    llm_config={\"config_list\": config},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is joe and you are a neurosurgeon.\",\n",
    "    llm_config={\"config_list\": config},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 12-26 23:59:56] {351} WARNING - Model llama3.2 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "Here's a short one:\n",
      "\n",
      "\"Moonlight whispers secrets night,\n",
      "A gentle breeze that whispers right.\n",
      "In the stillness, stars shine bright,\n",
      "A peaceful world, in pure delight.\"\n"
     ]
    }
   ],
   "source": [
    "agent2 = ConversableAgent(\n",
    "    \"chatbot1\",\n",
    "    llm_config={\"config_list\": config},\n",
    "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
    "    function_map=None,  # No registered functions, by default it is None.\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "reply = agent2.generate_reply(messages=[{\"content\": \"Tell me a short poem.\", \"role\": \"user\"}])\n",
    "print(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
