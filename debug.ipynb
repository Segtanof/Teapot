{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customs Brokers']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the folder name with current date and time\n",
    "folder_name = 'results/task_match_'+datetime.now().strftime(\"%d%m_%H%M\")+\"/\"\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\",\n",
    "                    handlers=[logging.FileHandler(\"execution_log.log\"), logging.StreamHandler()])\n",
    "\n",
    "# read dataset and drop columns\n",
    "job_statements = pd.read_excel(\"datasets/task_statements.xlsx\")\n",
    "job_statements.columns = job_statements.columns.str.lower()\n",
    "job_statements = job_statements.drop(labels=[\"incumbents responding\",\"date\",\"domain source\"], axis=1).rename(columns={\"o*net-soc code\":\"code\", \"task type\":\"type\", \"task id\": \"id\", \"task\":\"ref_task\"})\n",
    "job_statements = job_statements[job_statements[\"type\"].notna()]\n",
    "job_statements[\"ind\"] = job_statements[\"code\"].str[:2]\n",
    "job_statements = job_statements.groupby(\"title\").agg({\"ref_task\":list, \"ind\": \"first\"}).reset_index().sort_values(\"ind\")\n",
    "sampled_occupation = job_statements.groupby('ind', group_keys=False).sample(frac=0.05, random_state=1) #43 samples\n",
    "\n",
    "#for trial\n",
    "trial_df = sampled_occupation.sample(1, random_state= 1)\n",
    "test_sample_list =[trial_df.iloc[x][\"title\"] for x in range(len(trial_df))]\n",
    "test_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_des (title):\n",
    "    task_list = sampled_occupation.query(\"title == @title\")[\"ref_task\"].iloc[0]\n",
    "    return task_list\n",
    "\n",
    "def task_gen(title, model, system=None):  # [unchanged]\n",
    "    ref_task_count = len(get_des(title))\n",
    "    json_schema = {\"type\": \"object\", \"properties\": {\"occupation\": {\"type\": \"string\"}, \"tasks\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"minItems\": ref_task_count, \"maxItems\": ref_task_count}}, \"required\": [\"occupation\", \"tasks\"]}\n",
    "    query = f\"List exactly {ref_task_count} unique task statements that the occupation '{title}' would perform at work.\"\n",
    "    prompt_template = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")] if system else [(\"human\", \"{input}\")])\n",
    "    llm = model.with_structured_output(schema=json_schema, method=\"json_schema\")\n",
    "    prompt = prompt_template.invoke({\"input\": query})\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        tasks = response[\"tasks\"]\n",
    "        if len(tasks) != ref_task_count or len(set(tasks)) < len(tasks):\n",
    "            logging.warning(f\"Task issues for {title}: count {len(tasks)}/{ref_task_count}, uniques {len(set(tasks))}\")\n",
    "        return tasks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed for {title}: {e}\")\n",
    "        return [f\"Error: Task {i+1} for {title}\" for i in range(ref_task_count)]\n",
    "\n",
    "def process_title(args):\n",
    "    title, model_config, prompt = args\n",
    "    model = ChatOllama(**model_config)\n",
    "    start_time = datetime.now()\n",
    "    tasks = task_gen(title, model, system=prompt)\n",
    "    logging.info(f\"Single inference for {title}, duration: {datetime.now() - start_time}\")\n",
    "    return title, tasks\n",
    "\n",
    "def preProcessText(text):  # [unchanged]\n",
    "    processed = []\n",
    "    for doc in text:\n",
    "        if not isinstance(doc, str): doc = str(doc)\n",
    "        doc = re.sub(r\"\\\\n|\\W|\\d\", \" \", doc)\n",
    "        doc = re.sub(r'\\s+[a-z]\\s+|^[a-z]\\s+|\\s+', \" \", doc)\n",
    "        doc = re.sub(r'^\\s|\\s$', \"\", doc)\n",
    "        processed.append(doc.lower())\n",
    "    return processed\n",
    "\n",
    "def sbert_batch(ref_list, gen_list):\n",
    "    sim_model = SentenceTransformer(\"all-mpnet-base-v2\", similarity_fn_name=\"cosine\", device=\"cuda\")\n",
    "    embeddings_ref = sim_model.encode(ref_list, batch_size=32, convert_to_tensor=True)\n",
    "    embeddings_gen = sim_model.encode(gen_list, batch_size=32, convert_to_tensor=True)\n",
    "    return sim_model.similarity(embeddings_ref, embeddings_gen).cpu().numpy()\n",
    "\n",
    "def match_batch(ref_lists, gen_lists):\n",
    "    results = []\n",
    "    for ref_tasks, gen_tasks in zip(ref_lists, gen_lists):\n",
    "        ref_clean = preProcessText(ref_tasks)\n",
    "        gen_clean = preProcessText(gen_tasks)\n",
    "        matrix = sbert_batch(ref_clean, gen_clean)\n",
    "        row_ind, col_ind = linear_sum_assignment(1 - matrix)\n",
    "        avg_score = np.mean(matrix[row_ind, col_ind])\n",
    "        results.append((avg_score, matrix.tolist(), row_ind.tolist(), col_ind.tolist()))\n",
    "    return results\n",
    "\n",
    "def match_batch_parallel(ref_lists, gen_lists, num_processes=8):\n",
    "    chunk_size = max(1, len(ref_lists) // num_processes)\n",
    "    chunks = [(ref_lists[i:i + chunk_size], gen_lists[i:i + chunk_size]) for i in range(0, len(ref_lists), chunk_size)]\n",
    "    \n",
    "    def process_chunk(chunk):\n",
    "        refs, gens = chunk\n",
    "        return match_batch(refs, gens)\n",
    "    \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        chunk_results = pool.map(process_chunk, chunks)\n",
    "    \n",
    "    # Flatten results\n",
    "    results = []\n",
    "    for chunk in chunk_results:\n",
    "        results.extend(chunk)\n",
    "    return results\n",
    "\n",
    "# Replace in main script:\n",
    "def apply_match_batch(df):\n",
    "    ref_lists = df[\"ref_task\"].tolist()\n",
    "    gen_lists = df[\"gen_task\"].tolist()\n",
    "    results = match_batch_parallel(ref_lists, gen_lists, num_processes=8)\n",
    "    scores, matrices, ref_orders, gen_orders = zip(*results)\n",
    "    df[\"score\"] = scores\n",
    "    df[\"matrix\"] = matrices\n",
    "    df[\"ref_order\"] = ref_orders\n",
    "    df[\"gen_order\"] = gen_orders\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    {\"model\": \"llama3.2\", \"temperature\": 1, \"base_url\": \"http://127.0.0.1:11434\"},\n",
    "    {\"model\": \"llama3.1\", \"temperature\": 1, \"base_url\": \"http://127.0.0.1:11434\"}\n",
    "]\n",
    "prompts = {\n",
    "    \"no_prompt\": None,\n",
    "    \"prompt1\": \"You are an expert of this occupation: \\\"{title}\\\". Your task is to generate clear and concise task descriptions...\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 18:41:13,681 - Script started\n",
      "2025-03-19 18:41:13,683 - Processing model: llama3.2\n",
      "2025-03-19 18:41:14,511 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "llama3.2-no_prompt-0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "logging.info(\"Script started\")\n",
    "for model_config in model_configs:\n",
    "    model_name = model_config[\"model\"]\n",
    "    logging.info(f\"Processing model: {model_name}\")\n",
    "    model = ChatOllama(**model_config)\n",
    "    model.invoke(\"Warm-up prompt\")\n",
    "\n",
    "    for name, prompt in prompts.items():\n",
    "        if prompt:\n",
    "            start_time = datetime.now()\n",
    "            with open(f\"{folder_name}/sys_prompt.txt\", \"a\") as f:\n",
    "                f.write(prompt + \"\\n\")\n",
    "            logging.info(f\"Wrote prompt {name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "        all_results_df = trial_df.copy()\n",
    "        all_results_df[\"gen_task\"] = [None] * len(all_results_df)\n",
    "        all_results_df[\"iteration\"] = None\n",
    "\n",
    "        for i in range(2):\n",
    "            start_time = datetime.now()\n",
    "            with Pool(processes=1) as pool:\n",
    "                results = list(tqdm(\n",
    "                    pool.imap_unordered(process_title, [(title, model_config, prompt) for title in test_sample_list]),\n",
    "                    total=len(test_sample_list), desc=f\"{model_name}-{name}-{i}\"\n",
    "                ))\n",
    "            logging.info(f\"Multiprocessing for {model_name}-{name}-{i}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "            temp_df = trial_df.copy()\n",
    "            for title, tasks in results:\n",
    "                temp_df.loc[temp_df[\"title\"] == title, \"gen_task\"] = pd.Series([tasks]).values\n",
    "            temp_df[\"iteration\"] = i\n",
    "            all_results_df = pd.concat([all_results_df, temp_df], ignore_index=True)\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        all_results_df = apply_match_batch(all_results_df)\n",
    "        logging.info(f\"Batch matching for {model_name}-{name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        all_results_df = all_results_df.reset_index(drop=True)\n",
    "        with open(f\"{folder_name}/{model_name}_{name}_results.json\", \"w\") as f:\n",
    "            f.write(all_results_df.to_json(index=True))\n",
    "        logging.info(f\"Wrote results JSON for {model_name}-{name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "logging.info(\"Script completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 22:49:06,179 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-03-19 22:49:12,807 - Single inference for Customs Brokers, duration: 0:00:06.993114\n"
     ]
    }
   ],
   "source": [
    "x = process_title((\"Customs Brokers\", {\"model\": \"llama3.2\"}, \"You are an expert of this occupation. Your task is to generate clear and concise task descriptions.Start with a verb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_gen(title, model, system=None):  # [unchanged]\n",
    "    ref_task_count = len(get_des(title))\n",
    "    json_schema = {\"type\": \"object\", \"properties\": {\"occupation\": {\"type\": \"string\"}, \"tasks\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"minItems\": ref_task_count, \"maxItems\": ref_task_count}}, \"required\": [\"occupation\", \"tasks\"]}\n",
    "    query = \"List exactly \"+ str(ref_task_count) +\" unique task statements that the occupation \" + title + \"would perform at work.\"\n",
    "    prompt_template = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")] if system else [(\"human\", \"{input}\")])\n",
    "    llm = model.with_structured_output(schema=json_schema, method=\"json_schema\")\n",
    "    prompt = prompt_template.invoke({\"input\": query, \"title\": title})\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        tasks = response[\"tasks\"]\n",
    "        if len(tasks) != ref_task_count or len(set(tasks)) < len(tasks):\n",
    "            logging.warning(f\"Task issues for {title}: count {len(tasks)}/{ref_task_count}, uniques {len(set(tasks))}\")\n",
    "        return tasks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed for {title}: {e}\")\n",
    "        return [f\"Error: Task {i+1} for {title}\" for i in range(ref_task_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are an expert of this occupation: \\\"{title}\\\". Your task is to generate clear and concise task descriptions...\"\n",
    "# Invoke with both required variables\n",
    "# prompt = prompt_template.invoke({\"input\": query, \"title\": title})\n",
    "# query = \"List exactly 10 unique task statements that the occupation '{title}' would perform at work.\"\n",
    "\n",
    "# # Ensure the system message is included correctly\n",
    "# prompt_template = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", system),\n",
    "#     (\"human\", \"{input}\")\n",
    "# ])\n",
    "\n",
    "# # Invoke with both required variables\n",
    "# prompt = prompt_template.invoke({\"input\": query, \"title\": title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 23:36:37,284 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "x = task_gen(title, ChatOllama(model=\"llama3.2\"), system=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Verify shipment documentation against commercial invoices, bills of lading, and other relevant customs forms to ensure accuracy and completeness.',\n",
       " 'Evaluate compliance with relevant laws, regulations, and international trade agreements to minimize duty and tax liabilities.',\n",
       " 'Conduct research on product classification codes (HS Codes) to determine applicable tariffs and duties.',\n",
       " 'Prepare and submit export declarations to relevant authorities, including U.S. Customs and Border Protection (CBP) and the Treasury Inspector General for Tax Administration (TIGTA).',\n",
       " 'Coordinate with importers, exporters, and other stakeholders to gather necessary documentation and resolve any issues related to customs clearance.',\n",
       " 'Analyze commercial invoice and bill of lading discrepancies to identify potential errors or discrepancies in shipment details.',\n",
       " 'Communicate with carriers, forwarders, and other logistics providers to clarify shipment details and ensure smooth customs clearance.',\n",
       " 'Maintain up-to-date knowledge of changing regulations, laws, and trade agreements to provide informed guidance to clients.',\n",
       " 'Develop and implement effective compliance strategies to minimize risk and optimize customs benefits for clients.',\n",
       " \"Prepare and submit responses to CBP audits, which may include providing additional documentation or information to support client's claims.\",\n",
       " \"Monitor and respond to changes in global events, laws, and regulations that may impact clients' international trade activities.\",\n",
       " 'Collaborate with colleagues to share knowledge, best practices, and industry insights to enhance the overall customs brokerage service.',\n",
       " 'Conduct site visits to warehouses, distribution centers, or other facilities to verify compliance with customs regulations and ensure accurate documentation.',\n",
       " 'Investigate discrepancies in shipment details, such as weight, value, or country of origin, and negotiate resolutions with carriers or clients.',\n",
       " 'Provide guidance on customs forms, procedures, and requirements to new clients or those who are new to international trade.',\n",
       " 'Maintain accurate records and files for all client shipments, including commercial invoices, bills of lading, and customs documents.',\n",
       " 'Develop and maintain relationships with government agencies, logistics providers, and other stakeholders to ensure smooth customs clearance operations.',\n",
       " 'Stay informed about emerging trends and technologies in the customs brokerage industry, such as AI-powered risk assessment tools or blockchain-based supply chain management.',\n",
       " 'Create and implement training programs for new employees or existing staff on customs regulations, laws, and best practices.',\n",
       " 'Develop and manage client relationships to ensure high levels of customer satisfaction and loyalty.',\n",
       " 'Analyze business performance data to identify areas for improvement and optimize customs brokerage services for maximum efficiency and effectiveness.',\n",
       " \"Negotiate with carriers, forwarders, or other logistics providers to secure the best possible rates or terms for clients' shipments.\",\n",
       " 'Ensure compliance with all relevant laws, regulations, and industry standards, including those related to data protection, anti-money laundering, and terrorism financing prevention.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
