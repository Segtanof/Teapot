{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the folder name with current date and time\n",
    "folder_name = 'results/task_match_'+datetime.now().strftime(\"%d%m_%H%M\")+\"/\"\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\",\n",
    "                    handlers=[logging.FileHandler(\"execution_log.log\"), logging.StreamHandler()])\n",
    "\n",
    "# read dataset and drop columns\n",
    "job_statements = pd.read_excel(\"datasets/task_statements.xlsx\")\n",
    "job_statements.columns = job_statements.columns.str.lower()\n",
    "job_statements = job_statements.drop(labels=[\"incumbents responding\",\"date\",\"domain source\"], axis=1).rename(columns={\"o*net-soc code\":\"code\", \"task type\":\"type\", \"task id\": \"id\", \"task\":\"ref_task\"})\n",
    "job_statements = job_statements[job_statements[\"type\"].notna()]\n",
    "job_statements[\"ind\"] = job_statements[\"code\"].str[:2]\n",
    "job_statements = job_statements.groupby(\"title\").agg({\"ref_task\":list, \"ind\": \"first\"}).reset_index().sort_values(\"ind\")\n",
    "sampled_occupation = job_statements.groupby('ind', group_keys=False).sample(frac=0.05, random_state=1) #43 samples\n",
    "\n",
    "#for trial\n",
    "trial_df = sampled_occupation.sample(1, random_state= 1)\n",
    "test_sample_list =[trial_df.iloc[x][\"title\"] for x in range(len(trial_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_des (title):\n",
    "    task_list = sampled_occupation.query(\"title == @title\")[\"ref_task\"].iloc[0]\n",
    "    return task_list\n",
    "\n",
    "def task_gen(title, model, system=None):  # [unchanged]\n",
    "    ref_task_count = len(get_des(title))\n",
    "    json_schema = {\"type\": \"object\", \"properties\": {\"occupation\": {\"type\": \"string\"}, \"tasks\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"minItems\": ref_task_count, \"maxItems\": ref_task_count}}, \"required\": [\"occupation\", \"tasks\"]}\n",
    "    query = f\"List exactly {ref_task_count} unique task statements that the occupation '{title}' would perform at work.\"\n",
    "    prompt_template = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")] if system else [(\"human\", \"{input}\")])\n",
    "    llm = model.with_structured_output(schema=json_schema, method=\"json_schema\")\n",
    "    prompt = prompt_template.invoke({\"input\": query})\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        tasks = response[\"tasks\"]\n",
    "        if len(tasks) != ref_task_count or len(set(tasks)) < len(tasks):\n",
    "            logging.warning(f\"Task issues for {title}: count {len(tasks)}/{ref_task_count}, uniques {len(set(tasks))}\")\n",
    "        return tasks\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed for {title}: {e}\")\n",
    "        return [f\"Error: Task {i+1} for {title}\" for i in range(ref_task_count)]\n",
    "\n",
    "def process_title(args):\n",
    "    title, model_config, prompt = args\n",
    "    model = ChatOllama(**model_config)\n",
    "    start_time = datetime.now()\n",
    "    tasks = task_gen(title, model, system=prompt)\n",
    "    logging.info(f\"Single inference for {title}, duration: {datetime.now() - start_time}\")\n",
    "    return title, tasks\n",
    "\n",
    "def preProcessText(text):  # [unchanged]\n",
    "    processed = []\n",
    "    for doc in text:\n",
    "        if not isinstance(doc, str): doc = str(doc)\n",
    "        doc = re.sub(r\"\\\\n|\\W|\\d\", \" \", doc)\n",
    "        doc = re.sub(r'\\s+[a-z]\\s+|^[a-z]\\s+|\\s+', \" \", doc)\n",
    "        doc = re.sub(r'^\\s|\\s$', \"\", doc)\n",
    "        processed.append(doc.lower())\n",
    "    return processed\n",
    "\n",
    "def sbert_batch(ref_list, gen_list):\n",
    "    sim_model = SentenceTransformer(\"all-mpnet-base-v2\", similarity_fn_name=\"cosine\", device=\"cuda\")\n",
    "    embeddings_ref = sim_model.encode(ref_list, batch_size=32, convert_to_tensor=True)\n",
    "    embeddings_gen = sim_model.encode(gen_list, batch_size=32, convert_to_tensor=True)\n",
    "    return sim_model.similarity(embeddings_ref, embeddings_gen).cpu().numpy()\n",
    "\n",
    "def match_batch(ref_lists, gen_lists):\n",
    "    results = []\n",
    "    for ref_tasks, gen_tasks in zip(ref_lists, gen_lists):\n",
    "        ref_clean = preProcessText(ref_tasks)\n",
    "        gen_clean = preProcessText(gen_tasks)\n",
    "        matrix = sbert_batch(ref_clean, gen_clean)\n",
    "        row_ind, col_ind = linear_sum_assignment(1 - matrix)\n",
    "        avg_score = np.mean(matrix[row_ind, col_ind])\n",
    "        results.append((avg_score, matrix.tolist(), row_ind.tolist(), col_ind.tolist()))\n",
    "    return results\n",
    "\n",
    "def match_batch_parallel(ref_lists, gen_lists, num_processes=8):\n",
    "    chunk_size = max(1, len(ref_lists) // num_processes)\n",
    "    chunks = [(ref_lists[i:i + chunk_size], gen_lists[i:i + chunk_size]) for i in range(0, len(ref_lists), chunk_size)]\n",
    "    \n",
    "    def process_chunk(chunk):\n",
    "        refs, gens = chunk\n",
    "        return match_batch(refs, gens)\n",
    "    \n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        chunk_results = pool.map(process_chunk, chunks)\n",
    "    \n",
    "    # Flatten results\n",
    "    results = []\n",
    "    for chunk in chunk_results:\n",
    "        results.extend(chunk)\n",
    "    return results\n",
    "\n",
    "# Replace in main script:\n",
    "def apply_match_batch(df):\n",
    "    ref_lists = df[\"ref_task\"].tolist()\n",
    "    gen_lists = df[\"gen_task\"].tolist()\n",
    "    results = match_batch_parallel(ref_lists, gen_lists, num_processes=8)\n",
    "    scores, matrices, ref_orders, gen_orders = zip(*results)\n",
    "    df[\"score\"] = scores\n",
    "    df[\"matrix\"] = matrices\n",
    "    df[\"ref_order\"] = ref_orders\n",
    "    df[\"gen_order\"] = gen_orders\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    {\"model\": \"llama3.2\", \"temperature\": 1, \"base_url\": \"http://127.0.0.1:11434\"},\n",
    "    {\"model\": \"llama3.1\", \"temperature\": 1, \"base_url\": \"http://127.0.0.1:11434\"}\n",
    "]\n",
    "prompts = {\n",
    "    \"no_prompt\": None,\n",
    "    \"prompt1\": \"You are an expert of this occupation: \\\"{title}\\\". Your task is to generate clear and concise task descriptions...\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 18:41:13,681 - Script started\n",
      "2025-03-19 18:41:13,683 - Processing model: llama3.2\n",
      "2025-03-19 18:41:14,511 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "llama3.2-no_prompt-0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "logging.info(\"Script started\")\n",
    "for model_config in model_configs:\n",
    "    model_name = model_config[\"model\"]\n",
    "    logging.info(f\"Processing model: {model_name}\")\n",
    "    model = ChatOllama(**model_config)\n",
    "    model.invoke(\"Warm-up prompt\")\n",
    "\n",
    "    for name, prompt in prompts.items():\n",
    "        if prompt:\n",
    "            start_time = datetime.now()\n",
    "            with open(f\"{folder_name}/sys_prompt.txt\", \"a\") as f:\n",
    "                f.write(prompt + \"\\n\")\n",
    "            logging.info(f\"Wrote prompt {name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "        all_results_df = trial_df.copy()\n",
    "        all_results_df[\"gen_task\"] = [None] * len(all_results_df)\n",
    "        all_results_df[\"iteration\"] = None\n",
    "\n",
    "        for i in range(2):\n",
    "            start_time = datetime.now()\n",
    "            with Pool(processes=1) as pool:\n",
    "                results = list(tqdm(\n",
    "                    pool.imap_unordered(process_title, [(title, model_config, prompt) for title in test_sample_list]),\n",
    "                    total=len(test_sample_list), desc=f\"{model_name}-{name}-{i}\"\n",
    "                ))\n",
    "            logging.info(f\"Multiprocessing for {model_name}-{name}-{i}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "            temp_df = trial_df.copy()\n",
    "            for title, tasks in results:\n",
    "                temp_df.loc[temp_df[\"title\"] == title, \"gen_task\"] = pd.Series([tasks]).values\n",
    "            temp_df[\"iteration\"] = i\n",
    "            all_results_df = pd.concat([all_results_df, temp_df], ignore_index=True)\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        all_results_df = apply_match_batch(all_results_df)\n",
    "        logging.info(f\"Batch matching for {model_name}-{name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        all_results_df = all_results_df.reset_index(drop=True)\n",
    "        with open(f\"{folder_name}/{model_name}_{name}_results.json\", \"w\") as f:\n",
    "            f.write(all_results_df.to_json(index=True))\n",
    "        logging.info(f\"Wrote results JSON for {model_name}-{name}, duration: {datetime.now() - start_time}\")\n",
    "\n",
    "logging.info(\"Script completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
