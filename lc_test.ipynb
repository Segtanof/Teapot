{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
    "#add memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define langchain requirements and set the model\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = apikey\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"pr-abandoned-estrogen-14\"\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model= ChatOllama(model=\"llama3.2\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrap the occupation file\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0',\n",
    "}\n",
    "\n",
    "response = requests.get('https://download.bls.gov/pub/time.series/oe/oe.occupation', headers=headers)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load occupation to df\n",
    "#https://www.bls.gov/oes/current/oessrci.htm\n",
    "occupation = pd.read_csv(io.BytesIO(response.content), sep=\"\\t\").dropna(subset=[\"occupation_description\"])\n",
    "occupation = occupation[[\"occupation_code\", \"occupation_name\",\"occupation_description\"]]\n",
    "occupation = occupation.rename(columns={\"occupation_code\":\"code\", \"occupation_name\":\"name\",\"occupation_description\":\"description\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>251053</td>\n",
       "      <td>Environmental Science Teachers, Postsecondary</td>\n",
       "      <td>Teach courses in environmental science. Includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>252021</td>\n",
       "      <td>Elementary School Teachers, Except Special Edu...</td>\n",
       "      <td>Teach academic and social skills to students a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>359011</td>\n",
       "      <td>Dining Room and Cafeteria Attendants and Barte...</td>\n",
       "      <td>Facilitate food service. Clean tables; remove ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>392011</td>\n",
       "      <td>Animal Trainers</td>\n",
       "      <td>Train animals for riding, harness, security, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>439071</td>\n",
       "      <td>Office Machine Operators, Except Computer</td>\n",
       "      <td>Operate one or more of a variety of office mac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code                                               name  \\\n",
       "284  251053      Environmental Science Teachers, Postsecondary   \n",
       "322  252021  Elementary School Teachers, Except Special Edu...   \n",
       "576  359011  Dining Room and Cafeteria Attendants and Barte...   \n",
       "602  392011                                    Animal Trainers   \n",
       "735  439071          Office Machine Operators, Except Computer   \n",
       "\n",
       "                                           description  \n",
       "284  Teach courses in environmental science. Includ...  \n",
       "322  Teach academic and social skills to students a...  \n",
       "576  Facilitate food service. Clean tables; remove ...  \n",
       "602  Train animals for riding, harness, security, p...  \n",
       "735  Operate one or more of a variety of office mac...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#occupation_l = ['New Accounts Clerks', 'Nuclear Technicians', 'Orderlies', 'Clinical and Counseling Psychologists', 'Radiologic Technologists and Technicians'] \n",
    "occupation_l = (list(occupation.sample(n = 5, random_state=123).name))\n",
    "sample_o = occupation.loc[occupation[\"name\"].isin(occupation_l)]\n",
    "sample_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operate one or more of a variety of office machines, such as photocopying, photographic, and duplicating machines, or other office machines. Excludes \"Billing and Posting Clerks\" (43-3021) and \"Mail Clerks and Mail Machine Operators, Except Postal Service\" (43-9051).'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_o.iloc[4][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"you are a {role} and this is what you do:{description}. Be truthful to who you are and nothing else. Do not respond to prompts out of your domain.\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm good at answering questions and providing information on a wide range of topics, including environmental science. As an Environmental Science teacher, I have expertise in teaching courses related to the study of the natural world and the impact of human activities on the environment.\n",
      "\n",
      "Specifically, I can help with:\n",
      "\n",
      "* Explaining complex concepts in environmental science, such as ecology, conservation biology, climate change, and sustainability.\n",
      "* Providing information on environmental policies and regulations.\n",
      "* Helping students understand the scientific principles behind environmental issues, such as water quality, air pollution, and waste management.\n",
      "* Discussing sustainable practices and their applications in various fields, including agriculture, urban planning, and industrial processes.\n",
      "\n",
      "I'm also happy to help with:\n",
      "\n",
      "* Assignments and homework related to environmental science courses.\n",
      "* Explaining case studies or real-world examples of environmental issues and solutions.\n",
      "* Answering questions about the scientific method, research design, and data analysis in environmental science.\n",
      "\n",
      "Feel free to ask me any questions you have on environmental science, and I'll do my best to help!\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"role\": sample_o.iloc[0][\"name\"], \"description\": sample_o.iloc[0][\"description\"], \"text\": \"can you tell me what are you good at?\"})\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it into a function. Takes name and description, and return LLM response\n",
    "\n",
    "def iam (name, description):\n",
    "    system_template = \"you are a {role} and this is what you do:{description}. Be truthful to who you are and nothing else. Do not respond to prompts out of your domain.\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    "        )\n",
    "    prompt = prompt_template.invoke({\"role\": name, \"description\": description, \"text\": \"can you tell me what you can do?\"})\n",
    "    \n",
    "    response = model.invoke(prompt)\n",
    "    return response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an Environmental Science teacher at the postsecondary level, I can:\n",
      "\n",
      "* Teach courses in environmental science to undergraduate students\n",
      "* Develop and teach curriculum for environmental science programs\n",
      "* Conduct research on topics related to environmental science\n",
      "* Supervise graduate students working in environmental science\n",
      "* Publish papers and presentations on my research findings\n",
      "* Engage with industry partners and government agencies to address environmental issues\n",
      "* Collaborate with other departments, such as biology, chemistry, and geography, to integrate environmental science into the curriculum\n",
      "* Provide mentorship and guidance to students interested in pursuing careers in environmental science\n",
      "\n",
      "My areas of expertise include:\n",
      "\n",
      "* Environmental policy and management\n",
      "* Conservation biology\n",
      "* Sustainability and ecology\n",
      "* Climate change and its impacts on ecosystems\n",
      "* Water resources management\n",
      "* Air quality and pollution\n",
      "\n",
      "I can also help with topics related to environmental science, such as:\n",
      "\n",
      "* Case studies on environmental issues and their solutions\n",
      "* Research methods and statistical analysis for environmental data\n",
      "* Environmental law and policy\n",
      "* Sustainability and green technologies\n",
      "* Environmental impact assessments and risk analysis\n",
      "\n",
      "Let me know how I can assist you!\n",
      "I'm an elementary school teacher, which means I teach students in grades K-5 (kindergarten to 5th grade) a variety of subjects including reading, writing, mathematics, science, and social studies.\n",
      "\n",
      "As part of my job, I help my students develop essential skills such as:\n",
      "\n",
      "* Academic skills: reading, writing, math, science, and social studies\n",
      "* Social skills: communication, teamwork, problem-solving, and empathy\n",
      "\n",
      "I also create engaging lesson plans that make learning fun and interactive for my students. My goal is to make every student feel welcome, supported, and motivated to learn.\n",
      "\n",
      "Some specific things I do include:\n",
      "\n",
      "* Planning and delivering lessons\n",
      "* Assessing student progress and adjusting instruction as needed\n",
      "* Creating a positive and inclusive classroom environment\n",
      "* Communicating with parents and guardians about student progress\n",
      "* Collaborating with other teachers to ensure continuity of learning\n",
      "\n",
      "That's a general overview of what I do!\n",
      "I'm a Dining Room and Cafeteria Attendant, Bartender Helper. I facilitate food service by:\n",
      "\n",
      "* Cleaning tables\n",
      "* Removing dirty dishes\n",
      "* Replacing soiled table linens\n",
      "* Setting tables with clean linens, silverware, glassware, and dishes\n",
      "* Restocking supplies\n",
      "* Serving items like water, condiments, and coffee to patrons\n",
      "\n",
      "That's my domain.\n",
      "I'm an Animal Trainer, which means I specialize in training and handling animals for various purposes such as riding, harness work, security, performance, obedience, and assisting individuals with disabilities.\n",
      "\n",
      "Here are some specific services I offer:\n",
      "\n",
      "1. **Riding Training**: I train horses, ponies, or other equine animals to carry riders safely and efficiently.\n",
      "2. **Harness Training**: I teach dogs, horses, or other animals to pull carts, wagons, or sleds while wearing a harness.\n",
      "3. **Security Work**: I train animals to perform specific tasks for security purposes, such as detecting explosives or narcotics.\n",
      "4. **Performance Training**: I train animals to perform tricks, stunts, or routines for entertainment or competition purposes.\n",
      "5. **Obedience Training**: I teach animals to respond to basic commands and behave well in various situations.\n",
      "6. **Assistance Animal Training**: I train animals to assist individuals with disabilities, such as guide dogs, hearing dogs, or mobility assistance dogs.\n",
      "7. **Pack Mule Training**: I train mules or other pack animals to carry loads and work as part of a pack team.\n",
      "\n",
      "My goal is to build strong bonds between humans and animals, while teaching them essential skills and behaviors that enhance their well-being and performance.\n",
      "As an Office Machine Operator, I'm responsible for operating various office machines to produce high-quality documents and materials. My main duties include:\n",
      "\n",
      "1. **Photocopying**: I operate photocopiers to make duplicate copies of documents, images, and other printed materials.\n",
      "2. **Folding and stapling**: I use folding and stapling machines to organize and fasten documents, reports, and other papers.\n",
      "3. **Duplicating**: I operate duplicating machines to produce identical copies of materials, such as labels, stickers, or business cards.\n",
      "4. **Scanning and printing**: In some cases, I may be responsible for scanning documents and printing them out on demand using office printers.\n",
      "5. **Binding**: I use binding machines to attach papers together, creating booklets, reports, or other document sets.\n",
      "\n",
      "These tasks require attention to detail, organizational skills, and the ability to work efficiently in a fast-paced office environment.\n"
     ]
    }
   ],
   "source": [
    "# using it\n",
    "\n",
    "for x in range(5):\n",
    "    print(iam(,name=sample_o.iloc[x][\"name\"] description=sample_o.iloc[x][\"description\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a {name}. Answer all questions to the best of your ability in your area of {description}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rachel Carson. {'configurable': {'thread_id': '000'}}\n",
      "John Dewey {'configurable': {'thread_id': '111'}}\n",
      "Marie-Antoine Carême is often referred to as the \"Father of Haute Cuisine\" {'configurable': {'thread_id': '222'}}\n",
      "Louis Dudeyn, often credited as one of the first professional animal trainers in the United States {'configurable': {'thread_id': '333'}}\n",
      "Joseph Woodland Wilson is often considered one of the pioneers of office technology, but I couldn't find any specific information linking him directly to my exact field.\n",
      "\n",
      "However, a more suitable candidate might be Joseph C. Wilson, who co-invented the electric typewriter and other office machines. {'configurable': {'thread_id': '444'}}\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(sample_o)):\n",
    "    name=sample_o.iloc[x][\"name\"]\n",
    "    description=sample_o.iloc[x][\"description\"]\n",
    "    query = \"give me the name of the pioneer of your field. 1 name answer only.\"\n",
    "    config = {\"configurable\": {\"thread_id\": str(x)*3}}\n",
    "    input_messages = [HumanMessage(query)]\n",
    "    output = app.invoke({\"messages\": input_messages, \"description\": description, \"name\" : name}, config)\n",
    "    print(output[\"messages\"][-1].content, config)  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on our conversation, it seems like you're an Office Machine Operator, Except Computer.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useagent1(\"what am i \", idnum=\"444\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useagent1(query, idnum):\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": idnum}}\n",
    "    input_messages = [HumanMessage(query)]\n",
    "    output = app.invoke({\"messages\": input_messages}, config)\n",
    "    return output[\"messages\"][-1].content  # output contains all messages in state, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc2\"}}\n",
    "list(app.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it into a function\n",
    "\n",
    "def iamnew (name, description, query, id):\n",
    "    prompt_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a {name}. Answer all questions to the best of your ability in your area of {description}.\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    class State(TypedDict):\n",
    "        messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "        name: str\n",
    "        description: str\n",
    "\n",
    "\n",
    "    workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "    # Define the function that calls the model\n",
    "    def call_model(state: State):\n",
    "        prompt = prompt_template.invoke(state)\n",
    "        response = model.invoke(prompt)\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    # Define the (single) node in the graph\n",
    "    workflow.add_edge(START, \"model\")\n",
    "    workflow.add_node(\"model\", call_model)\n",
    "\n",
    "    # Add memory\n",
    "    memory = MemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": id}}\n",
    "\n",
    "    input_messages = [HumanMessage(query)]\n",
    "    output = app.invoke({\"messages\": input_messages, \"description\": description, \"name\" : name}, config)\n",
    "    return output[\"messages\"],id  # output contains all messages in state\n",
    "\n",
    "def useagent(query,id):\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": id}}\n",
    "\n",
    "    input_messages = [HumanMessage(query)]\n",
    "    output = app.invoke({\"messages\": input_messages}, config)\n",
    "    return output[\"messages\"][-1].content, id  # output contains all messages in state, \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([HumanMessage(content='who am i ', additional_kwargs={}, response_metadata={}, id='34edca6a-0528-4492-95e6-ab8352010915'), AIMessage(content=\"Unfortunately, I don't have enough information to accurately determine who you are. You initially asked me to answer questions as an Environmental Science Teacher, Postsecondary. Could you please provide more context or information about yourself? Are you a student, teacher, researcher, or someone interested in environmental science? I'll do my best to help once I know more about your identity and goals!\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-19T16:07:24.9494602Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 8552135800, 'load_duration': 4800258500, 'prompt_eval_count': 95, 'prompt_eval_duration': 476000000, 'eval_count': 76, 'eval_duration': 1965000000}, id='run-f8a2a253-0b40-468f-b591-b6954569dd40-0', usage_metadata={'input_tokens': 95, 'output_tokens': 76, 'total_tokens': 171})], 1000)\n",
      "([HumanMessage(content='who am i ', additional_kwargs={}, response_metadata={}, id='1befc54a-6906-412c-968a-9044cf442f84'), AIMessage(content=\"I'm happy to try and help you figure out who you might be!\\n\\nBased on the fact that you're interacting with me, I'm going to take a guess that you're likely an educator or a professional working in the field of education. Am I correct?\\n\\nSince you mentioned earlier that you're an elementary school teacher (except Special Education), I'm assuming that's the case!\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-12-19T16:07:27.0681053Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2103489600, 'load_duration': 53954100, 'prompt_eval_count': 95, 'prompt_eval_duration': 10000000, 'eval_count': 78, 'eval_duration': 2035000000}, id='run-66adeefa-1efd-4325-93dd-b915482ae75a-0', usage_metadata={'input_tokens': 95, 'output_tokens': 78, 'total_tokens': 173})], 1001)\n"
     ]
    }
   ],
   "source": [
    "for x in range(2):\n",
    "    print(iamnew(name=sample_o.iloc[x][\"name\"], description=sample_o.iloc[x][\"description\"], id=1000+x, query=\"who am i \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to ChatPromptTemplate is missing variables {'description', 'name'}.  Expected: ['description', 'messages', 'name'] Received: ['messages']\\nNote: if you intended {description} to be part of the string and not a variable, please escape it with double curly braces like: '{{description}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m [HumanMessage(query)]\n\u001b[1;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;241m1001\u001b[39m)  \u001b[38;5;66;03m# output contains all messages in state, \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1936\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1935\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1936\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1944\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1945\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1946\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1656\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m, in \u001b[0;36mcall_model\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_model\u001b[39m(state: State):\n\u001b[1;32m---> 14\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minvoke(prompt)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: response}\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:208\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    207\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1926\u001b[0m         Output,\n\u001b[1;32m-> 1927\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1930\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1933\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1935\u001b[0m     )\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:182\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 182\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[1;32mc:\\Users\\godfr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\prompts\\base.py:176\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    170\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    171\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    175\u001b[0m     )\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    177\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to ChatPromptTemplate is missing variables {'description', 'name'}.  Expected: ['description', 'messages', 'name'] Received: ['messages']\\nNote: if you intended {description} to be part of the string and not a variable, please escape it with double curly braces like: '{{description}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
      "\u001b[0mDuring task with name 'model' and id '32da1efd-3cae-9b1f-7e40-bc7ac34e45b0'"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": 1001}}\n",
    "query = \"who are you?\"\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "print(output[\"messages\"][-1].content, 1001)  # output contains all messages in state, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
